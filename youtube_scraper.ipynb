{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Scraper for Video Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Set Up API Key\n",
    "> Import necessary libraries and set up the YouTube API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time  # Import the time module for rate limiting\n",
    "from dotenv import load_dotenv # import .env file for API key\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up YouTube API key\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters and Functions\n",
    "> Define categories, maximum results, minimum samples per category, and functions for sanitizing descriptions and scraping YouTube data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categories and other parameters\n",
    "categories = ['Travel Blogs', 'Science and Technology', 'Food', 'Manufacturing', 'History', 'Art and Music']\n",
    "max_results = 50\n",
    "min_samples_per_category = 1700\n",
    "\n",
    "# Initialize an empty list to store all videos\n",
    "all_videos = []\n",
    "\n",
    "# Function to sanitize video descriptions\n",
    "def sanitize_description(description):\n",
    "    # Use regular expressions to remove unwanted information\n",
    "    # For example, removing email addresses, phone numbers, etc.\n",
    "    # Modify this based on your specific needs\n",
    "    cleaned_description = re.sub(r'\\S+@\\S+', '', description)\n",
    "    return cleaned_description\n",
    "\n",
    "# Function to scrape YouTube data for a given category\n",
    "def scrape_youtube_data(category):\n",
    "    videos = []\n",
    "    while len(videos) < min_samples_per_category:\n",
    "        for query in [f'{category} videos', f'{category} documentary']:\n",
    "            try:\n",
    "                # Make a YouTube API search request\n",
    "                request = youtube.search().list(\n",
    "                    q=query,\n",
    "                    part='id,snippet',\n",
    "                    type='video',\n",
    "                    maxResults=max_results\n",
    "                )\n",
    "                response = request.execute()\n",
    "                items = response.get('items', [])\n",
    "\n",
    "                # Loop through the retrieved videos\n",
    "                for item in items:\n",
    "                    video_id = item['id']['videoId']\n",
    "                    title = item['snippet']['title']\n",
    "\n",
    "                    # Make a YouTube API video request\n",
    "                    video_request = youtube.videos().list(\n",
    "                        part='snippet',\n",
    "                        id=video_id\n",
    "                    )\n",
    "                    video_response = video_request.execute()\n",
    "                    description = video_response['items'][0]['snippet']['description']\n",
    "\n",
    "                    # Sanitize the description using the defined function\n",
    "                    cleaned_description = sanitize_description(description)\n",
    "\n",
    "                    # Append video information to the list\n",
    "                    videos.append({'Video id': video_id, 'Title': title, 'Description': cleaned_description, 'Category': category})\n",
    "            except Exception as e:\n",
    "                print(f\"Error in API request: {str(e)}\")\n",
    "\n",
    "            # Add rate limiting to avoid hitting API rate limits\n",
    "            time.sleep(1)  # Sleep for 1 second between requests\n",
    "\n",
    "        # Break the loop if there are no more results\n",
    "        if not items:\n",
    "            break\n",
    "\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape YouTube Data\n",
    "> Loop through each category and scrape YouTube data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in API request: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/search?q=Travel+Blogs+videos&part=id%2Csnippet&type=video&maxResults=50&key=AIzaSyB09NK-QQpTfZW-S3kHOfK1vKR8-KoY1f0&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">\n",
      "Error in API request: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/search?q=Travel+Blogs+documentary&part=id%2Csnippet&type=video&maxResults=50&key=AIzaSyB09NK-QQpTfZW-S3kHOfK1vKR8-KoY1f0&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'items' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Vaibhav\\Desktop\\youtube_scraper\\youtube_scraper.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vaibhav/Desktop/youtube_scraper/youtube_scraper.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Loop through each category and scrape YouTube data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vaibhav/Desktop/youtube_scraper/youtube_scraper.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m category \u001b[39min\u001b[39;00m categories:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Vaibhav/Desktop/youtube_scraper/youtube_scraper.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     videos \u001b[39m=\u001b[39m scrape_youtube_data(category)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vaibhav/Desktop/youtube_scraper/youtube_scraper.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     all_videos\u001b[39m.\u001b[39mextend(videos)\n",
      "\u001b[1;32mc:\\Users\\Vaibhav\\Desktop\\youtube_scraper\\youtube_scraper.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vaibhav/Desktop/youtube_scraper/youtube_scraper.ipynb#X21sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)  \u001b[39m# Sleep for 1 second between requests\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vaibhav/Desktop/youtube_scraper/youtube_scraper.ipynb#X21sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39m# Break the loop if there are no more results\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Vaibhav/Desktop/youtube_scraper/youtube_scraper.ipynb#X21sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m items:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vaibhav/Desktop/youtube_scraper/youtube_scraper.ipynb#X21sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vaibhav/Desktop/youtube_scraper/youtube_scraper.ipynb#X21sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mreturn\u001b[39;00m videos\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'items' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# Loop through each category and scrape YouTube data\n",
    "for category in categories:\n",
    "    videos = scrape_youtube_data(category)\n",
    "    all_videos.extend(videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame and Save to CSV\n",
    "> Create a DataFrame and save the data to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame and CSV file\n",
    "df = pd.DataFrame(all_videos)\n",
    "df.to_csv('youtube_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The YouTube data has been successfully scraped and stored in a CSV file (`youtube_data.csv`). This dataset can be used for text classification tasks based on video descriptions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
